import json
import os
import numpy as np
import librosa
import librosa.display
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import io
import base64
from fastdtw import fastdtw
from scipy.spatial.distance import euclidean
from xhtml2pdf import pisa

REFERENCE_FILE = "storage/reference_melody.json"
TEACHER_AUDIO_FILE = "storage/audio_samples/teacher_reference.wav"

def save_reference_melody(notes):
    os.makedirs(os.path.dirname(REFERENCE_FILE), exist_ok=True)
    with open(REFERENCE_FILE, "w") as f:
        json.dump(notes, f)

def load_reference_melody():
    if not os.path.exists(REFERENCE_FILE): return None
    with open(REFERENCE_FILE, "r") as f: return json.load(f)

# --- PDF GENERATION HELPERS ---
def fig_to_base64(fig):
    buf = io.BytesIO()
    fig.savefig(buf, format='png', bbox_inches='tight')
    plt.close(fig)
    buf.seek(0)
    return base64.b64encode(buf.read()).decode('utf-8')

def generate_pdf_graphs(y_ref, sr_ref, y_stu, sr_stu):
    """Generates static Matplotlib graphs specifically for the PDF report."""
    graphs = {}
    
    # 1. Pitch Contour Overlay (Green/Red)
    f0_ref, _, _ = librosa.pyin(y_ref, fmin=50, fmax=1000, sr=sr_ref)
    f0_stu, _, _ = librosa.pyin(y_stu, fmin=50, fmax=1000, sr=sr_stu)
    times_ref = librosa.times_like(f0_ref, sr=sr_ref)
    times_stu = librosa.times_like(f0_stu, sr=sr_stu)

    fig1 = plt.figure(figsize=(10, 4))
    plt.plot(times_ref, f0_ref, label='Reference', color='green', linewidth=2, alpha=0.7)
    plt.plot(times_stu, f0_stu, label='Student', color='red', linestyle='--', linewidth=2, alpha=0.9)
    plt.title("Intonation Comparison")
    plt.xlabel("Time (s)")
    plt.ylabel("Frequency (Hz)")
    plt.legend()
    plt.grid(True, alpha=0.3)
    graphs['pitch'] = fig_to_base64(fig1)

    # 2. Heatmap (Spectral)
    fig2 = plt.figure(figsize=(10, 4))
    chroma = librosa.feature.chroma_cqt(y=y_stu, sr=sr_stu)
    librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', cmap='coolwarm')
    plt.colorbar()
    plt.title("Harmonic Analysis")
    graphs['heatmap'] = fig_to_base64(fig2)

    return graphs

def generate_performance_pdf(student_audio_path, score, feedback_list):
    if not os.path.exists(TEACHER_AUDIO_FILE): return None

    # Load Audio
    y_ref, sr_ref = librosa.load(TEACHER_AUDIO_FILE)
    y_stu, sr_stu = librosa.load(student_audio_path)

    # Generate Graphs
    graphs = generate_pdf_graphs(y_ref, sr_ref, y_stu, sr_stu)

    # HTML Template
    html_content = f"""
    <html>
    <head>
        <style>
            body {{ font-family: Helvetica, sans-serif; color: #333; padding: 20px; }}
            .header {{ text-align: center; border-bottom: 2px solid #2f5aff; padding-bottom: 20px; margin-bottom: 20px; }}
            .score-box {{ background: #f0f4ff; padding: 15px; border-radius: 10px; text-align: center; margin-bottom: 20px; }}
            .score {{ font-size: 40px; color: #2f5aff; font-weight: bold; }}
            .section {{ margin-bottom: 30px; }}
            h2 {{ color: #444; border-left: 5px solid #ff0055; padding-left: 10px; }}
            .img-container {{ text-align: center; margin: 20px 0; border: 1px solid #ddd; padding: 10px; }}
            img {{ width: 100%; max-width: 700px; }}
            .feedback-item {{ background: #fff; border-bottom: 1px solid #eee; padding: 10px; }}
        </style>
    </head>
    <body>
        <div class="header">
            <h1>Music Tutor Analysis Report</h1>
            <p>Generated by AI Performance Tutor</p>
        </div>

        <div class="score-box">
            <div>Performance Score</div>
            <div class="score">{score}%</div>
        </div>

        <div class="section">
            <h2>1. Pitch Accuracy (Intonation)</h2>
            <p>The <b>Green line</b> represents the teacher's reference pitch. The <b>Red dashed line</b> is your performance.</p>
            <div class="img-container">
                <img src="data:image/png;base64,{graphs['pitch']}" />
            </div>
        </div>

        <div class="section">
            <h2>2. Tonal Harmony</h2>
            <p>This heatmap shows the energy distribution of your notes over time.</p>
            <div class="img-container">
                <img src="data:image/png;base64,{graphs['heatmap']}" />
            </div>
        </div>

        <div class="section">
            <h2>3. Detailed Feedback</h2>
            {''.join([f'<div class="feedback-item">{item["message"]}</div>' for item in feedback_list])}
        </div>
    </body>
    </html>
    """

    # Convert to PDF
    pdf_buffer = io.BytesIO()
    pisa_status = pisa.CreatePDF(io.BytesIO(html_content.encode('utf-8')), dest=pdf_buffer)
    
    if pisa_status.err: return None
    pdf_buffer.seek(0)
    return pdf_buffer

# --- EXISTING FUNCTIONS (Kept for Dashboard) ---
def generate_heatmap(y, sr):
    plt.figure(figsize=(10, 4))
    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)
    librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', cmap='coolwarm')
    plt.colorbar()
    plt.title('Harmonic Content')
    plt.tight_layout()
    buf = io.BytesIO()
    plt.savefig(buf, format='png', transparent=True)
    plt.close()
    buf.seek(0)
    return base64.b64encode(buf.read()).decode('utf-8')

def generate_graph_data(student_audio_path, teacher_notes, student_notes):
    # Default empty structure to prevent frontend crashes
    default_data = { "pitch_data": [], "rhythm_data": [], "piano_roll": [], "heatmap": None }
    
    if not os.path.exists(TEACHER_AUDIO_FILE): 
        return default_data

    try:
        y_ref, sr_ref = librosa.load(TEACHER_AUDIO_FILE)
        y_stu, sr_stu = librosa.load(student_audio_path)
        dur_ref = librosa.get_duration(y=y_ref, sr=sr_ref)

        default_data["heatmap"] = generate_heatmap(y_stu, sr_stu)

        f0_ref, _, _ = librosa.pyin(y_ref, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))
        f0_stu, _, _ = librosa.pyin(y_stu, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))
        
        target_points = 100
        if len(f0_ref) == 0 or len(f0_stu) == 0: return default_data

        indices_ref = np.linspace(0, len(f0_ref) - 1, target_points).astype(int)
        indices_stu = np.linspace(0, len(f0_stu) - 1, target_points).astype(int)
        times = np.linspace(0, dur_ref, target_points)

        for i in range(target_points):
            val_ref = float(f0_ref[indices_ref[i]]) if not np.isnan(f0_ref[indices_ref[i]]) else None
            val_stu = float(f0_stu[indices_stu[i]]) if not np.isnan(f0_stu[indices_stu[i]]) else None
            default_data["pitch_data"].append({ 
                "seconds": float(times[i]), 
                "teacher": val_ref, 
                "student": val_stu 
            })

        rms_ref = librosa.feature.rms(y=y_ref)[0]
        rms_stu = librosa.feature.rms(y=y_stu)[0]
        if rms_ref.max() > 0: rms_ref = (rms_ref - rms_ref.min()) / (rms_ref.max() - rms_ref.min() + 1e-6)
        if rms_stu.max() > 0: rms_stu = (rms_stu - rms_stu.min()) / (rms_stu.max() - rms_stu.min() + 1e-6)

        ind_r = np.linspace(0, len(rms_ref)-1, target_points).astype(int)
        ind_s = np.linspace(0, len(rms_stu)-1, target_points).astype(int)

        for i in range(target_points):
            val_r = float(rms_ref[ind_r[i]])
            val_s = float(rms_stu[ind_s[i]])
            default_data["rhythm_data"].append({ 
                "seconds": float(times[i]),
                "teacher_top": val_r, "teacher_bottom": -val_r,
                "student_top": val_s, "student_bottom": -val_s 
            })

        for n in teacher_notes:
            default_data["piano_roll"].append({ "x": n['start'], "y": n['pitch'], "duration": n['duration'], "type": "teacher" })
        for n in student_notes:
            default_data["piano_roll"].append({ "x": n['start'], "y": n['pitch'], "duration": n['duration'], "type": "student" })

        return default_data
    except Exception as e:
        print(f"Error in graphs: {e}")
        return default_data

def calculate_feedback(student_notes, student_audio_path):
    teacher_notes = load_reference_melody()
    if not teacher_notes or not student_notes:
        return {"score": 0, "comments": ["No data."], "detailed_breakdown": [], "graph_data": None}

    teacher_seq = np.array([n['pitch'] for n in teacher_notes]).reshape(-1, 1)
    student_seq = np.array([n['pitch'] for n in student_notes]).reshape(-1, 1)
    distance, path = fastdtw(teacher_seq, student_seq, dist=euclidean)
    
    max_len = max(len(teacher_seq), len(student_seq))
    final_score = max(0, min(100, int(100 - ((distance / max_len) * 5.0))))

    detailed_breakdown = []
    seen_teacher = set()
    for t_idx, s_idx in path:
        if t_idx in seen_teacher: continue
        seen_teacher.add(t_idx)
        
        t_val = teacher_notes[t_idx]['pitch']
        s_val = student_notes[s_idx]['pitch']
        t_note_name = librosa.midi_to_note(int(round(t_val)), unicode=False)
        s_note_name = librosa.midi_to_note(int(round(s_val)), unicode=False)
        
        diff = s_val - t_val
        status = "match" if abs(diff) < 0.5 else "error"
        
        if status == "match":
            msg = f"Note {t_idx+1} ({t_note_name}): Perfect match!"
        elif diff > 0:
            msg = f"Note {t_idx+1} ({t_note_name}): Too High (You sang {s_note_name})"
        else:
            msg = f"Note {t_idx+1} ({t_note_name}): Too Low (You sang {s_note_name})"
            
        detailed_breakdown.append({"index": t_idx+1, "status": status, "message": msg})

    graph_data = generate_graph_data(student_audio_path, teacher_notes, student_notes)
    
    return {
        "score": final_score,
        "comments": ["Great job!"] if final_score > 80 else ["Keep practicing."],
        "detailed_breakdown": detailed_breakdown,
        "graph_data": graph_data
    }